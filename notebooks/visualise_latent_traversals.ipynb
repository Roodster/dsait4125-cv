{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 \n",
    "from src.dataset import DspritesDataset, get_dataloaders_2element\n",
    "from src.networks import MAGANet  # Replace with your actual model import\n",
    "from src.args import Args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_PATH =\"../outputs/run_prod_maga/seed_1_240320250829/models/model_2element.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_output(output, name):\n",
    "    \n",
    "    if isinstance(output, tuple):\n",
    "        output = output[0]\n",
    "\n",
    "    if output.dim() == 4:  # [B, C, H, W]\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        num_channels = min(5, output.size(1))  # Show up to 5 channels\n",
    "        for i in range(num_channels):\n",
    "            plt.subplot(1, num_channels, i + 1)\n",
    "            plt.imshow(output[0, i].cpu().detach().numpy(), cmap='gray')\n",
    "            plt.title(f'{name} Ch{i}')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Cannot visualize {name}: unexpected shape {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_latents_traversals(model, x1, x2, save_file='traversals.gif'):\n",
    "    # Get the base latent vector z\n",
    "    with torch.no_grad():\n",
    "        base_z, mu1, logvar1, _, _ = model.encoder(x1, x2)\n",
    "\n",
    "    # Define traversal parameters with modified pattern:\n",
    "    # 0 -> +delta -> -delta -> 0\n",
    "    delta = 2.0    # Range of traversal\n",
    "    \n",
    "    # Create the steps sequence: 0 -> +delta -> -delta -> 0\n",
    "    steps_up = np.linspace(0, delta, 25)  # From original to +delta\n",
    "    steps_down = np.linspace(delta, -delta, 50)  # From +delta to -delta\n",
    "    steps_back = np.linspace(-delta, 0, 25)  # From -delta back to original\n",
    "    steps = np.concatenate([steps_up, steps_down, steps_back])\n",
    "    num_steps = len(steps)  # Total number of steps in the sequence\n",
    "\n",
    "    # Create directory for saving GIFs\n",
    "    os.makedirs('traversals', exist_ok=True)\n",
    "\n",
    "    # Create a list to hold the generated images for all components\n",
    "    all_generated_images = []\n",
    "\n",
    "    # Prepare the ground truth and varying images with labels\n",
    "    gt_image = x1.cpu().numpy()[0, 0, :, :]  # Assuming x1 is [1, C, H, W]\n",
    "    varying_image = x2.cpu().numpy()[0, 0, :, :]  # Assuming x2 is [1, C, H, W]\n",
    "    gt_image = (gt_image * 255).astype(np.uint8)\n",
    "    varying_image = (varying_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Add a white boundary around the ground truth and varying images\n",
    "    gt_image = np.pad(gt_image, pad_width=5, mode='constant', constant_values=255)\n",
    "    varying_image = np.pad(varying_image, pad_width=5, mode='constant', constant_values=255)\n",
    "\n",
    "    # Perform latent traversal for each component\n",
    "    latent_dim = base_z.size(1)\n",
    "    for i in range(latent_dim):\n",
    "        # Generate modified z vectors for component i\n",
    "        z_traversals = []\n",
    "        for step in steps:\n",
    "            z_mod = base_z.clone()\n",
    "            z_mod[0, i] = base_z[0, i] + step  # Modify i-th component\n",
    "            z_traversals.append(z_mod)\n",
    "        z_traversals = torch.cat(z_traversals, dim=0)  # Shape: [num_steps, latent_dim]\n",
    "\n",
    "        x_pivots = x1.repeat(num_steps, 1, 1, 1)  # Repeat x_pivot for num_steps times\n",
    "\n",
    "        # Generate images from modified z vectors\n",
    "        with torch.no_grad():\n",
    "            generated_images = model.decoder(z=z_traversals, x1=x_pivots)  # Shape: [num_steps, 1, H, W]\n",
    "\n",
    "        # Convert tensors to numpy arrays for visualization\n",
    "        generated_images = generated_images.cpu().numpy()  # [num_steps, 1, H, W]\n",
    "        generated_images = generated_images[:, 0, :, :]    # [num_steps, H, W]\n",
    "\n",
    "        # Prepare images for GIF (scale to [0, 255] and convert to uint8)\n",
    "        images = [(img * 255).astype(np.uint8) for img in generated_images]\n",
    "\n",
    "        # Add a white boundary around each generated image\n",
    "        bordered_images = []\n",
    "        for img in images:\n",
    "            bordered_img = np.pad(img, pad_width=5, mode='constant', constant_values=255)  # Add a 5-pixel white border\n",
    "            bordered_images.append(bordered_img)\n",
    "        \n",
    "        # Append the bordered images for this component to the all_generated_images list\n",
    "        all_generated_images.append(bordered_images)\n",
    "\n",
    "    # Create a single image for all components including ground truth and varying images\n",
    "    final_images = []\n",
    "    for step in range(num_steps):\n",
    "        # Concatenate images for each step horizontally\n",
    "        component_images = [all_generated_images[i][step] for i in range(latent_dim)]\n",
    "        combined_image = np.concatenate(component_images, axis=1)  # This is 2D: [H, W_combined]\n",
    "        \n",
    "        # Stack GT and varying images to have the same number of dimensions as combined_image\n",
    "        final_row = np.concatenate([gt_image, combined_image, varying_image], axis=1)\n",
    "        \n",
    "        # Create label areas with proper dimensions\n",
    "        h = final_row.shape[0]  # Height of the combined image\n",
    "        label_gt = np.full((h, 50), 255, dtype=np.uint8)  # White label background\n",
    "        label_varying = np.full((h, 50), 255, dtype=np.uint8)  # White label background\n",
    "        \n",
    "        # Add the labels to the image\n",
    "        final_row_with_labels = np.concatenate([label_gt, final_row, label_varying], axis=1)\n",
    "        \n",
    "        # Add text labels\n",
    "        label_img = final_row_with_labels.copy()\n",
    "        cv2.putText(label_img, 'Pivot', (0, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(label_img, 'GT', (label_img.shape[1] - 45, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        final_images.append(label_img)\n",
    "\n",
    "    # Save the final combined GIF\n",
    "    final_gif_path = os.path.join('traversals', save_file)\n",
    "    imageio.mimsave(final_gif_path, final_images, duration=0.05)  # 0.05s per frame for smoother animation\n",
    "    print(f\"Saved combined GIF at {final_gif_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAGANet(\n",
       "  (encoder): Encoder(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (7): ReLU()\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): FlowNet(\n",
       "    (affine): Affine(\n",
       "      (fc_M): Linear(in_features=10, out_features=4096, bias=True)\n",
       "    )\n",
       "    (flow_modules): Sequential(\n",
       "      (0): FlowModule(\n",
       "        (squeeze): SqueezeLayer()\n",
       "        (flow_steps): Sequential(\n",
       "          (0): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): FlowModule(\n",
       "        (squeeze): SqueezeLayer()\n",
       "        (flow_steps): Sequential(\n",
       "          (0): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): FlowModule(\n",
       "        (squeeze): SqueezeLayer()\n",
       "        (flow_steps): Sequential(\n",
       "          (0): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): FlowStep(\n",
       "            (act_norm): ActNorm()\n",
       "            (inv_conv): Invertible1x1Conv()\n",
       "            (coupling): AdditiveCoupling(\n",
       "              (net): Sequential(\n",
       "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (unsqueeze): Sequential(\n",
       "      (0): UnsqueezeLayer()\n",
       "      (1): UnsqueezeLayer()\n",
       "      (2): UnsqueezeLayer()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "args  = Args(file=\"../data/configs/default.yaml\")\n",
    "model = MAGANet(args).to(device)  # Adjust parameters as per your model\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_output = False\n",
    "# Load dataset with the correct output format\n",
    "train_data = DspritesDataset(\"../data/2d/train.npz\", single_output=single_output)\n",
    "test_data = DspritesDataset(\"../data/2d/test.npz\", single_output=single_output)\n",
    "\n",
    "# Choose the correct data loader function\n",
    "if  \"maga\" in args.model_name:\n",
    "    train_loader, test_loader = get_dataloaders_2element(\n",
    "        train_data, test_data,\n",
    "        batch_size=1\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs = []\n",
    "\n",
    "n_images = 10\n",
    "for i, (x1, x2) in enumerate(train_loader):\n",
    "\n",
    "    x_pivot, x_varying= x1.to(device), x2.to(device)\n",
    "    pairs.append([x_pivot, x_varying])\n",
    "    if i + 1 == n_images:\n",
    "        break\n",
    "    \n",
    "\n",
    "# pairs = []\n",
    "# image_ids = [4345, 43423, 34231, 123232]\n",
    "# for i, (x1, x2) in enumerate(train_loader):\n",
    "#     if i + 1 == max(image_ids):\n",
    "#         break\n",
    "\n",
    "#     if i in image_ids:\n",
    "#         x_pivot, x_varying= x1.to(device), x2.to(device)\n",
    "#         visualize_image_output(x_pivot, \"pivot\")\n",
    "\n",
    "#         visualize_image_output(x_varying, \"x_varying\")\n",
    "\n",
    "#         pairs.append([x_pivot, x_varying])\n",
    "\n",
    "    \n",
    "\n",
    "visualize_image_output(x_pivot, \"pivot\")\n",
    "\n",
    "visualize_image_output(x_varying, \"x_varying\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined GIF at traversals/traversals_0.gif\n",
      "Saved combined GIF at traversals/traversals_1.gif\n",
      "Saved combined GIF at traversals/traversals_2.gif\n",
      "Saved combined GIF at traversals/traversals_3.gif\n",
      "Saved combined GIF at traversals/traversals_4.gif\n",
      "Saved combined GIF at traversals/traversals_5.gif\n",
      "Saved combined GIF at traversals/traversals_6.gif\n",
      "Saved combined GIF at traversals/traversals_7.gif\n",
      "Saved combined GIF at traversals/traversals_8.gif\n",
      "Saved combined GIF at traversals/traversals_9.gif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (x1, x2) in enumerate(pairs):\n",
    "    visualise_latents_traversals(model=model, x1=x1, x2=x2, save_file=f\"traversals_{i}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
